---
title: 'Week Six'
date: 2024-03-12
permalink: /posts/2024/03/blog-post-17/
tags:
  - research
  - my honors project
---

Promising results and images developed in the past week!

# Contents

- [Tasks Completed](#tasks)
- [Timeline](#calendar)
- [Goals](#moving)


---


<a name="tasks"></a>
# Tasks Completed 
- SURF Abstract Completed & Turned In
- Finished and Submitted Grant Application
- Fouind out the German's and Brits stole my idea (the prior is modeled by a GMM, but *tbh they did it better*)


# The Gaussian Mixture VAE
- In 2016 this guy published Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders (>600 citations)
  - "variant of the variational autoencoder model (VAE) with a Gaussian mixture as a prior distribution, with the goal of performing unsupervised clustering through deep generative models"
  - I'm not entirely sure what is going on as far as the math and implementating, but looking at the graphs they have made it is exactly what we wanted to do
  - The GitHub repo that hosts this project implemented the GMVAE in *lua*.
  - Today we'll take a look at the GMVAE and discuss how it may work for our project.
- As part of a masters thesis at a German School, someone made "Latent space conditioning for improved classification and anomaly detection"
  - They take ideas from the GMVAE and implemnent homogeneity and completeness of each GMM
  - Their model, "the CL-VAE produces a clear latent space fitting and automatic separation between classes."
  - Sounds promising, we could use majority/minority class label
- I think three things
  - These models are hard to implement and probably hard to converge (*they said that, but I just also think that*)
  - We do need some sort of clustering for imbalanced learning in the latent space, and this seems like the most solid avenue at the moment
  - The CL-VAE could be used to un-bias data. By trying to find a clusters that are not homogenous and complete, we force our model to not cluster based on sensiitve attribute, if that makes sense



<a name="calendar"></a>
# Calendar

| Week | Days    | Content    | 
| :---:   | :---: | :---: |
| Week 6 | March 5 - 12 | Busy week ahead (exams, Data Nexus Workshop), maybe a smaller amount of work than usual | 
| Week 7 | March 12-19 | Get this GM-VAE working and try it on a couple datasets |
| Week 8 | March 19-April 2 | Work on SURF presentation, presentation for IRIS (Danielle's conference), etc. |





<a name="questions"></a>
# Questions Raised
- What points should my presentations/posters hit?

<a name="moving"></a>
# Moving Forward

## Short-Term Goals
- Implement GM-VAE
- Learn some lua



## Long-Term Goals
- Get presentations ready

---
title: 'Week Four'
date: 2023-10-02
permalink: /posts/2023/10/blog-post-4/
tags:
  - research
  - my honors project
---

This is the fourth blog post for my honors thesis. 

# Contents

- [Tasks Completed](#tasks)
- [Narrative Update](#narrative)
- [Forked the CTGAN Package](#forking)
- [Measured Reconstruction Ability of TVAE with Encoder](#measuring)
- [Played around with Decision Trees](#forest)
- [Interpolated in the Latent Space](#latent)
- [Questions](#questions)
- [Goals](#moving)

---


<a name="tasks"></a>
# Tasks Completed 
- Fixed first section of the narrative
- Forked CTGAN package and have access to encoder
- Measured Reconstruction Ability of TVAE
- Tried to make *synthetic random forest* to see initial results
- Played around with latent space interpolation

---

<a name="narrative"></a>
# Narrative
- Made changes to the sections reviewed last week
- Will make changes to the rest of it and send it over after the rest has been reviewed.
- Being reviewed at workshop October 5.
- Will have a very done draft this Friday. 


<a name="forking"></a>
# Forking the CTGAN Package
- Before the CTGAN package did not allow access to certain things, such as the encoder and the transformer in TVAE
- There is now access to the encoder of the TVAE, **need to go back in and add the transformer as an accessible variable**.

<a name="measuring"></a>
# Measured Reconstruction Ability of TVAE
- Using the encoder portion of TVAE, I was able to measure the reconstruction of TVAE
- Normalized both dataframes (min-max normalization) and measured the euclidean distance between each observation and its reconstructed counterpart. [This image](https://github.com/claytonmclamb/claytonmmclamb.github.io/blob/master/images/histogramreco.png) visualizes the distribution of reconstruction error. It is an F-Distribution with a mean slightly below one, which is good. 

<a name="forest"></a>
# Synthetic Random Forest
- In Wine Quality, a random forest with ten estimators performs at a 79% accuracy.
- I tried to make something I would call a "synthetic forest." Randomly sampling from the dataframe and modelling a TVAE, then sampling 250 observations from the TVAE to model a decision tree resulted in a 68% accuracy.
- I think there is a lot of room for improvement in the algorithm to get it near the accuracy in a random forest.

<a name="latent"></a>
# Latent Space Interpolation
- With access to the encoders, we can now interpolate in the latent space.
- I took two observations, and ran them through the encoder.
- The encoder returns the mean, standard deviation, and log variance.
- I took the halfway point between the mean and standard deviation and to create a new point
- This point reconstructed almost exactly halfway through each of the original observations (*I can show my code in the meeting*)

---
<a name="questions"></a>
# Questions
- I don't really have any at this point in time. 

---




<a name="moving"></a>
# Moving Forward

## Short-Term Goals
- Completely finish narrative
- Get signature from mentor and department head
- Proof read
- Make corrections
- Get budget
- Get mentor CV

## Long-Term Goals
- Get accepted with no revisions
- Submit by fall break (**next Wednesday**)

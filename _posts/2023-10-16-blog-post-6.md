---
title: 'Week Five'
date: 2023-10-16
permalink: /posts/2023/10/blog-post-6/
tags:
  - research
  - my honors project
---

This is the sixth blog post for my honors thesis. It is (**oficially**) the last post before the thesis is proposed!

# Contents

- [Tasks Completed](#tasks)
- [Everything Ready to Submit Proposal by Wednesday](#narrative)
- [SMOTEBoost](#smote)
- [SMOTE Methods Experimented](#methods)
- [Questions](#questions)
- [Goals](#Goals)


---


<a name="tasks"></a>
# Tasks Completed 

- [Got feedback for final draft of narrative (cutting bagging)](#narrative)
- [Read SMOTEBoost](#boost)
- [Experimented in the latent space of TVAE](#methods)

---

<a name="narrative"></a>
# Narrative
- After feeback, the only thing left to do is cut bagging and submit the proposal.



<a name="boost"></a>
# SMOTEBoost
- Read the SMOTEBoost paper
- [This](https://medium.com/urbint-engineering/using-smoteboost-and-rusboost-to-deal-with-class-imbalance-c18f8bf5b805) article explains SMOTEBoost well.
- Before each boosting step, new synthetic examples are generated for the minority class
- The article and paper say there is promise, but results are not great.
- This (in my opinion) may be due to constraints and SMOTE methods used (*the section below discusses these methods*)

<a name="methods"></a>
# SMOTE Methods
- In the TVAE, the bottleneck contains 128 distributions (mean, std) for each compressed observation.
- Now with access to the encoder portion of the TVAE, we can see/represent these distributions.
- Over fall break, I experimented with three methods to generate new distribtions based on existing ones:
  - Linear
  - MidPoint
  - Geometric/Convex Hull
- The results from each method for generating distributions can be seen in the Google Doc [here.](https://docs.google.com/document/d/1CXvd_Xg7uSA2IgtWy1qMOgroiiqKiD-qHNvHwL89Rtk/edit?usp=sharing)
- The midpoint method centers itself arounf (0, 1) the most, followed by linear, and then convex hull.


<a name="questions"></a>
# Questions Raised
- How would you determine the best interpolation/SMOTE method? Is there some metric of success, or do you just perform the method, make a classifier, and measure the results that way?
- The first step, VAE-SMOTE, is the experimentation of SMOTE methods? (like above)

<a name="moving"></a>
# Moving Forward

## Short-Term Goals
- Make a function to get all 128 distributions for each SMOTE technique.
- Find more implementation of SMOTE techniques (K-Means included, etc.)


## Long-Term Goals
- Apply to NCUR
  - Travel grant application by November 3
